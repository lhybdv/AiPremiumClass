{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18ddfb77-5ace-4e4e-af25-4ebeafef0f7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 张量（Tensor）：\n",
    "# 张量（Tensor）是pytorch中的基本单位，也是深度学习框架构成的重要组成。\n",
    "# 我们可以先把张量看做是⼀个容器，⾥⾯承载了需要运算的数据。\n",
    "import numpy as np\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7aededb1-5663-4f81-84f6-a164ffaa2360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "# 张量可以直接从数据中创建。数据类型是⾃动推断的。\n",
    "data = [[1,2],[3,4]]\n",
    "x_data = torch.tensor(data)\n",
    "print(x_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3762e07e-33c4-4a96-8e5f-c5ac3a309c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#从NumPy数组,张量可以从NumPy数组创建\n",
    "data = [[1,2],[3,4]]\n",
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf7157d5-c449-4c5c-8351-b72d786c78c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1],\n",
      "        [1, 1]])\n",
      "tensor([[0.9467, 0.2822],\n",
      "        [0.2803, 0.0779]])\n"
     ]
    }
   ],
   "source": [
    "#从另⼀个张量：除非明确覆盖，否则新张量保留参数张量的属性（形状，数据类型）\n",
    "x_ones = torch.ones_like(x_data)#创建一个像x_datade张量\n",
    "print(x_ones)\n",
    "x_rand = torch.rand_like(x_data,dtype=torch.float)#覆盖x_data的数据类型\n",
    "print(x_rand)#生成一个像x_data的张量，随机生成0-1的浮点数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a8df0b8-ca2c-4c34-b64d-072d5e2c4c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0859, 0.1515, 0.1170],\n",
      "        [0.9136, 0.1658, 0.0716]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "#使用随机值或者常量\n",
    "#shape 是张量维度的元组。在下⾯的函数中，它决定了输出张量的维度。\n",
    "shape = (2,3)#2行3列\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "print(rand_tensor)\n",
    "print(ones_tensor)\n",
    "print(zeros_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aeb4d5c9-604e-45de-94ce-1c401858ddc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64) tensor([[0.5262, 0.5300, 0.6766],\n",
      "        [0.0137, 0.5506, 0.4628],\n",
      "        [0.6640, 0.8951, 0.5696],\n",
      "        [0.2458, 0.9017, 0.3241],\n",
      "        [0.5237, 0.4176, 0.3019]])\n",
      "torch.Size([5, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0000,  1.4737,  1.9474,  2.4211,  2.8947,  3.3684,  3.8421,  4.3158,\n",
       "         4.7895,  5.2632,  5.7368,  6.2105,  6.6842,  7.1579,  7.6316,  8.1053,\n",
       "         8.5789,  9.0526,  9.5263, 10.0000])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#其它⼀些创建⽅法\n",
    "# 基于现有tensor构建，但使⽤新值填充\n",
    "m = torch.ones(5,3,dtype=torch.double)\n",
    "n = torch.rand_like(m,dtype=torch.float)\n",
    "print(m,n)\n",
    "print(m.size())\n",
    "\n",
    "#均匀分布（二维）\n",
    "torch.rand(5,3)#（0-1之间随机采样）\n",
    "#标准正态分布\n",
    "torch.randn(5,3)#每个元素都是从标准正态分布（均值为 0，标准差为 1 的正态分布）中随机采样，\n",
    "# 离散正态分布\n",
    "torch.normal(mean=.0,std=1.0,size=(5,3))#生成0-1之间的随机数，\n",
    "# 线性间隔向量(返回⼀个1维张量，包含在区间start和end上均匀间隔的steps个点)\n",
    "torch.linspace(start=1,end=10,steps=20)#在1-10之间均匀的生成20个数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b4676347-541c-4b54-91cc-30823ad5ac7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.Size([3, 4])\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# 张量的属性：\n",
    "# 张量的属性描述了张量的形状、数据类型和存储它们的设备。\n",
    "# 以对象的⻆度来判断，张量可以看做是具有特征和⽅法的对象。\n",
    "tensor = torch.rand(3,4)\n",
    "print(tensor.dtype)\n",
    "print(tensor.shape)\n",
    "print(tensor.device)#在哪运行\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8cd6064-c39f-427f-a6a4-feb6eca3355c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 张量运算：\n",
    "# 默认情况下，张量是在 CPU 上创建的。我们可以使⽤使⽤.to() ⽅法明确地将张量移动到 GPU (GPU可⽤的情况下)。\n",
    "#设置张量在GPU上运算\n",
    "# if torch.cuda.is_available():\n",
    "#     tensor = tensor.to'cuda')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f3902811-31f4-4ccd-91c4-d27526328a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "#张量的索引和切⽚：\n",
    "tensor = torch.ones(4,4)\n",
    "# print(tensor[0])\n",
    "# print(tensor[0:3])\n",
    "# tensor[:,0]#取弟0列所有元素\n",
    "# tensor[...,-1]#取第负一列的所有数据（取出所有列表中最后一个特征）\n",
    "tensor[:,1] = 0 #取出所有列表中第一个特征（第一列）赋值为0\n",
    "print(tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f0e8097c-e6b0-401b-a942-48c26c0f38f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# 张量的拼接\n",
    "# 可以使⽤ torch.cat ⽤来连接指定维度的⼀系列张量。\n",
    "# 另⼀个和 torch.cat 功能类似的函数是torch.stack\n",
    "t1 = torch.cat([tensor,tensor,tensor],dim=1)\n",
    "print(t1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7f96466f-392a-4136-b22d-e21a8dcf0bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]])\n",
      "z1的值是 {tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 算数运算：计算两个张量之间矩阵乘法的集中方式y1, y2, y3 最后的值是⼀样的 dot\n",
    "y1 = tensor @ tensor.T#协方差矩阵可以通过 X @ X.T 来计算（其中 X 是数据矩阵）\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "\n",
    "y3 = torch.rand_like(tensor)\n",
    "torch.matmul(tensor,tensor.T,out=y3)\n",
    "#以上三种方法都一样，（钟意第一种）\n",
    "print(y3)\n",
    "# 计算张量逐元素相乘的⼏种⽅法。 z1, z2, z3 最后的值是⼀样的。\n",
    "z1 = tensor * tensor#每个元素和自己相乘\n",
    "print(f'z1的值是',{z1})\n",
    "\n",
    "z2 = tensor.mul(tensor)\n",
    "\n",
    "z3 = torch.rand_like(tensor)\n",
    "torch.mul(tensor,tensor,out=z3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "976c91e2-0227-4a08-8dc0-b2fcb51f37c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.0 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "# 单元素张量:如果⼀个单元素张量，例如将张量的值聚合计算，可以使⽤ item() ⽅法将其转换为Python 数值\n",
    "agg = tensor.sum()\n",
    "agg_item = agg.item()\n",
    "print(agg_item,type(agg_item))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9fdcf7af-5a61-41c8-8d43-1f057ea29eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#in-place操作：把计算结果存储到当前操作数中的操作就称为就地操作。\n",
    "#含义和pandas中inPlace参数的含义⼀样\n",
    "#pytorch中，这些操作是由带有下划线 _ 后缀的函数表⽰。\n",
    "#例如：x.copy_(y) ,  x.t_() , 将改变 x ⾃⾝的值。\n",
    "\n",
    "print(tensor,'\\n')\n",
    "# tensor.add_(5)\n",
    "# print(tensor)\n",
    "\n",
    "# In-place操作虽然节省了⼀部分内存，但在计算导数时可能会出现问题，因为它会⽴即丢失历史记录。\n",
    "# 因此，不⿎励使⽤它们。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "87f7d8b2-249d-4fea-aa4d-69f3ffed28ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#与numpy之间的转换\n",
    "# CPU 和 NumPy 数组上的张量共享底层内存位置，所以改变⼀个另⼀个也会变。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7bd9eac0-3c5d-44a5-8bdf-45449400ba32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "#张量到numpy数组\n",
    "t = torch.ones(5)\n",
    "print(t)\n",
    "n = t.numpy()\n",
    "print(n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b8a6264e-233e-443e-add5-c342daff1f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "# 张量值的变更也反映在关联的NumPy 数组中\n",
    "t.add_(1)\n",
    "print(t)\n",
    "print(n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8af2e097-fdf1-4695-aace-086b91267c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Numpy数组到张量\n",
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d4e46819-7ddd-4943-ba5e-3a29a658a329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "#NumPy 数组的变化也反映在张量中。\n",
    "np.add(n,1,out=n)\n",
    "print(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c39d95b-c709-4134-b842-963efceae3f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
