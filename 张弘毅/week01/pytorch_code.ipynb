{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "#直接从数据\n",
    "import torch\n",
    "data = [[1,2],[3,4]]\n",
    "x_data = torch.tensor(data)\n",
    "print(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2]\n",
      "tensor([1, 2])\n"
     ]
    }
   ],
   "source": [
    "#从numpy数组\n",
    "import numpy as np\n",
    "np_array = np.array([1,2])\n",
    "print(np_array)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "print(x_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor:\n",
      " {x_ones} \n",
      "\n",
      "Random Tensor:\n",
      " tensor([[0.6275, 0.9388],\n",
      "        [0.8184, 0.9562]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data)\n",
    "print(\"Ones Tensor:\\n {x_ones} \\n\")\n",
    "x_rand = torch.rand_like(x_data,dtype = torch.float)\n",
    "print(f\"Random Tensor:\\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor:\n",
      " tensor([[0.6596, 0.5374, 0.6829],\n",
      "        [0.4719, 0.5662, 0.7561]]) \n",
      "\n",
      "Ones Tensor:\n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "shape = (2,3,)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "print(f\"Random Tensor:\\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor:\\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor:\\n {zeros_tensor} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor大小: torch.Size([5, 3])\n",
      "均匀分布: tensor([[0.7256, 0.4797, 0.3477],\n",
      "        [0.0225, 0.4847, 0.4486],\n",
      "        [0.4196, 0.2427, 0.5288],\n",
      "        [0.7488, 0.0816, 0.8895],\n",
      "        [0.3221, 0.5823, 0.1590]])\n",
      "标准正态分布: tensor([[ 1.1043, -0.6216,  0.0381],\n",
      "        [-0.1079,  1.9860,  0.7866],\n",
      "        [ 1.5295, -1.7750,  0.9918],\n",
      "        [ 2.8878, -0.6834,  1.4195],\n",
      "        [ 1.2079, -0.5800, -0.2673]])\n",
      "离散正态分布: tensor([[ 1.1144,  1.0319, -1.2978],\n",
      "        [ 0.0374, -0.9366, -0.8577],\n",
      "        [-0.1560,  0.6148,  2.0899],\n",
      "        [-0.5353,  1.2735, -0.5444],\n",
      "        [-2.2436, -0.4417, -0.5683]])\n",
      "线性间隔向量: tensor([ 1., 10.])\n"
     ]
    }
   ],
   "source": [
    "# 基于现有tensor构建，但使用新值填充\n",
    "import torch\n",
    "m = torch.ones(5,3, dtype = torch.double)\n",
    "n = torch.rand_like(m, dtype = torch.float)\n",
    "#获取tensor大小\n",
    "print(\"tensor大小:\",m.size())\n",
    "#均匀正态分布\n",
    "print(\"均匀分布:\",torch.rand(5,3))\n",
    "#标准正态分布\n",
    "print(\"标准正态分布:\",torch.randn(5,3))\n",
    "#离散正态分布\n",
    "print(\"离散正态分布:\",torch.normal(mean = .0, std = 1.0, size = (5,3)))\n",
    "#线性间隔向量（返回1个1维张量，包含在区间start和end上均匀间隔的steps个点）\n",
    "print(\"线性间隔向量:\", torch.linspace(start = 1, end = 10, steps = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of tensor:torch.Size([3, 4])\n",
      "datetype of tensor:torch.float32\n",
      "device tensor is stored on:cpu\n"
     ]
    }
   ],
   "source": [
    "#Tensor属性\n",
    "tensor = torch.rand(3,4)\n",
    "print(f\"shape of tensor:{tensor.shape}\")\n",
    "print(f\"datetype of tensor:{tensor.dtype}\")\n",
    "print(f\"device tensor is stored on:{tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first row: tensor([1., 1., 1., 1.])\n",
      "first column: tensor([1., 1., 1., 1.])\n",
      "last column: tensor([1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "#Tensor的索引和切片\n",
    "tensor = torch.ones(4,4)\n",
    "print(\"first row:\",tensor[0])\n",
    "print(\"first column:\",tensor[:,0])\n",
    "print(\"last column:\",tensor[...,-1])\n",
    "tensor[:,1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n",
      "torch.Size([4, 12])\n"
     ]
    }
   ],
   "source": [
    "#tensor的拼接\n",
    "t1 = torch.cat([tensor,tensor,tensor],dim=1)\n",
    "print(t1)\n",
    "print(t1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]])\n",
      "tensor([[ 14.,  32.,  50.],\n",
      "        [ 32.,  77., 122.],\n",
      "        [ 50., 122., 194.]])\n",
      "tensor([[ 14.,  32.,  50.],\n",
      "        [ 32.,  77., 122.],\n",
      "        [ 50., 122., 194.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.arange(1,10,dtype=torch.float32).reshape(3,3)\n",
    "print(tensor)\n",
    "y1 = tensor @ tensor.T\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "print(y1)\n",
    "print(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "#单元素张量\n",
    "tensor = torch.arange(2,10)\n",
    "agg = tensor.sum()\n",
    "agg_item = agg.item()\n",
    "print(agg_item,type(agg_item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor值: tensor([1, 2, 3, 4, 5])\n",
      "tensor([1, 2, 3, 4, 5]) \n",
      "\n",
      "tensor([ 6,  7,  8,  9, 10])\n"
     ]
    }
   ],
   "source": [
    "# in place\n",
    "tensor = torch.arange(1,6)\n",
    "print(\"tensor值:\",tensor)\n",
    "print(tensor,\"\\n\")\n",
    "tensor.add_(5)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_name",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
