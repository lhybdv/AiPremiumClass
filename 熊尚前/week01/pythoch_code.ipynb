{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch基础\n",
    "Pytorch是一个开源的深度学习框架，由Facebook人工智能研究院（FAIR）开发。它是基于Python语言的，提供了丰富的工具和库，用于构建和训练深度学习模型。\n",
    "\n",
    "# 张量（Tensor)\n",
    "张量是Pytorch中的基本数据结构，类似于NumPy中的数组。它可以表示标量、向量、矩阵和更高维的数据。张量可以在GPU上进行加速计算，因此在深度学习中被广泛使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "# 直接从数据\n",
    "torch.tensor([[1,2],[3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# 从numpy数组\n",
    "import numpy as np\n",
    "np_array = np.array([[1,2],[3,4]])\n",
    "data = torch.from_numpy(np_array)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int32"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.2610, 0.2720],\n",
      "        [0.1192, 0.2043]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 从另一个张量\n",
    "data = [[1, 2],[3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "x_one = torch.ones_like(x_data) # 保留x_data的属性\n",
    "print(f\"Ones Tensor: \\n {x_one} \\n\")\n",
    "# 覆盖x_data的数据类型\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float)\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.5451, 0.8391, 0.1885],\n",
      "        [0.4484, 0.4894, 0.6320],\n",
      "        [0.4599, 0.3978, 0.6165]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# 使用随机值或者常量值\n",
    "# shap：是张量维度的元组。\n",
    "shape = (3,3,)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "tensor([[0.5911, 0.3129, 0.9298],\n",
      "        [0.4209, 0.6880, 0.4891],\n",
      "        [0.7492, 0.0379, 0.8435]])\n",
      "torch.Size([3, 3])\n",
      "tensor([[0.7231, 0.6424, 0.7277],\n",
      "        [0.7017, 0.2829, 0.0495],\n",
      "        [0.5032, 0.5720, 0.8877]])\n",
      "tensor([[-0.7736, -1.5465,  0.6998],\n",
      "        [-0.2717, -1.7299,  1.4661],\n",
      "        [-0.5432,  1.0709,  0.8985]])\n",
      "tensor([[-1.1930,  0.0582,  0.1646],\n",
      "        [-0.2606,  0.0927,  0.1349],\n",
      "        [ 0.2950, -0.8724, -0.2026]])\n"
     ]
    }
   ],
   "source": [
    "# 基于现有的tensor构建，但使用新值填充\n",
    "m = torch.ones(3,3,dtype=torch.double)\n",
    "print(m)\n",
    "n = torch.rand_like(m,dtype=torch.float)\n",
    "print(n)\n",
    "# 获取tensor的大小\n",
    "print(m.size())\n",
    "# 均匀分布\n",
    "print(torch.rand(3,3))\n",
    "# 标准正态分布\n",
    "print(torch.randn(3,3))\n",
    "# 离散正态分布\n",
    "print(torch.normal(mean=.1, std=1.0,size=(3,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7252, 0.8593, 0.5948, 0.7472, 0.6886],\n",
      "        [0.5026, 0.2360, 0.8548, 0.2300, 0.6790],\n",
      "        [0.7746, 0.3303, 0.9144, 0.8687, 0.7464],\n",
      "        [0.7275, 0.9464, 0.1500, 0.7834, 0.0898]])\n",
      "torch.Size([4, 5])\n",
      "torch.float32\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# 张量的属性\n",
    "# 张量的属性描述了张量的形状、数据类型和存储它们的设备。以对象的角度来判断，张量可以看作是具有特征和方法的对象。\n",
    "tensor = torch.rand(4,5)\n",
    "print(tensor)\n",
    "print(tensor.shape)\n",
    "print(tensor.dtype)\n",
    "print(tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# 判断是否支持gpu\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4057, 0.0889, 0.4281, 0.8296, 0.8342],\n",
      "        [0.3447, 0.1277, 0.6114, 0.3122, 0.6062],\n",
      "        [0.1132, 0.3991, 0.3863, 0.3336, 0.2873],\n",
      "        [0.5786, 0.2719, 0.0670, 0.8815, 0.1948],\n",
      "        [0.7571, 0.3181, 0.2030, 0.2541, 0.3470]])\n",
      "第一行tensor([0.4057, 0.0889, 0.4281, 0.8296, 0.8342])\n",
      "第一列tensor([0.4057, 0.3447, 0.1132, 0.5786, 0.7571])\n",
      "最后已列 tensor([0.8342, 0.6062, 0.2873, 0.1948, 0.3470])\n",
      "最后一列tensor([0.8342, 0.6062, 0.2873, 0.1948, 0.3470])\n",
      "tensor([[0.4057, 0.0889, 1.0000, 0.8296, 0.8342],\n",
      "        [0.3447, 0.1277, 1.0000, 0.3122, 0.6062],\n",
      "        [0.1132, 0.3991, 1.0000, 0.3336, 0.2873],\n",
      "        [0.5786, 0.2719, 1.0000, 0.8815, 0.1948],\n",
      "        [0.7571, 0.3181, 1.0000, 0.2541, 0.3470]])\n"
     ]
    }
   ],
   "source": [
    "# 张量的切片和索引\n",
    "tensor = torch.rand(5, 5)\n",
    "print(tensor)\n",
    "print(\"第一行%s\" % tensor[0])\n",
    "print(\"第一列{}\".format(tensor[:,0]))\n",
    "print(\"最后已列\", tensor[...,-1])\n",
    "print(f\"最后一列{tensor[:,-1]}\")\n",
    "\n",
    "tensor[:,2] = 1\n",
    "print(tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4057, 0.0889, 1.0000, 0.8296, 0.8342, 0.4057, 0.0889, 1.0000, 0.8296,\n",
      "         0.8342, 0.4057, 0.0889, 1.0000, 0.8296, 0.8342],\n",
      "        [0.3447, 0.1277, 1.0000, 0.3122, 0.6062, 0.3447, 0.1277, 1.0000, 0.3122,\n",
      "         0.6062, 0.3447, 0.1277, 1.0000, 0.3122, 0.6062],\n",
      "        [0.1132, 0.3991, 1.0000, 0.3336, 0.2873, 0.1132, 0.3991, 1.0000, 0.3336,\n",
      "         0.2873, 0.1132, 0.3991, 1.0000, 0.3336, 0.2873],\n",
      "        [0.5786, 0.2719, 1.0000, 0.8815, 0.1948, 0.5786, 0.2719, 1.0000, 0.8815,\n",
      "         0.1948, 0.5786, 0.2719, 1.0000, 0.8815, 0.1948],\n",
      "        [0.7571, 0.3181, 1.0000, 0.2541, 0.3470, 0.7571, 0.3181, 1.0000, 0.2541,\n",
      "         0.3470, 0.7571, 0.3181, 1.0000, 0.2541, 0.3470]])\n",
      "tensor([[0.8113, 0.1777, 2.0000, 1.6591, 1.6684, 0.8113, 0.1777, 2.0000, 1.6591,\n",
      "         1.6684, 0.8113, 0.1777, 2.0000, 1.6591, 1.6684],\n",
      "        [0.6893, 0.2553, 2.0000, 0.6243, 1.2125, 0.6893, 0.2553, 2.0000, 0.6243,\n",
      "         1.2125, 0.6893, 0.2553, 2.0000, 0.6243, 1.2125],\n",
      "        [0.2264, 0.7983, 2.0000, 0.6672, 0.5746, 0.2264, 0.7983, 2.0000, 0.6672,\n",
      "         0.5746, 0.2264, 0.7983, 2.0000, 0.6672, 0.5746],\n",
      "        [1.1572, 0.5438, 2.0000, 1.7630, 0.3897, 1.1572, 0.5438, 2.0000, 1.7630,\n",
      "         0.3897, 1.1572, 0.5438, 2.0000, 1.7630, 0.3897],\n",
      "        [1.5143, 0.6362, 2.0000, 0.5082, 0.6940, 1.5143, 0.6362, 2.0000, 0.5082,\n",
      "         0.6940, 1.5143, 0.6362, 2.0000, 0.5082, 0.6940]])\n",
      "torch.Size([5, 15])\n"
     ]
    }
   ],
   "source": [
    "# 张量的拼接\n",
    "x1 = torch.cat([tensor,tensor,tensor],dim=1)\n",
    "print(x1)\n",
    "print(x1 * 2)\n",
    "print(x1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]])\n",
      "tensor([[ 14.,  32.,  50.],\n",
      "        [ 32.,  77., 122.],\n",
      "        [ 50., 122., 194.]])\n",
      "tensor([[ 14.,  32.,  50.],\n",
      "        [ 32.,  77., 122.],\n",
      "        [ 50., 122., 194.]])\n",
      "tensor([[ 14.,  32.,  50.],\n",
      "        [ 32.,  77., 122.],\n",
      "        [ 50., 122., 194.]])\n"
     ]
    }
   ],
   "source": [
    "# 算术运算\n",
    "tensor = torch.arange(1, 10, dtype=torch.float32)\n",
    "print(tensor)\n",
    "tensor = tensor.reshape(3, 3)\n",
    "print(tensor)\n",
    "# 计算张量之间矩阵乘法的几种方式。\n",
    "x1 = tensor@tensor.T\n",
    "x2 = tensor.matmul(tensor.T)\n",
    "x3 = torch.rand_like(tensor)\n",
    "torch.matmul(tensor, tensor.T, out=x3)\n",
    "print(x1)\n",
    "print(x2)\n",
    "print(x3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  4.,  9.],\n",
      "        [16., 25., 36.],\n",
      "        [49., 64., 81.]])\n",
      "tensor([[ 1.,  4.,  9.],\n",
      "        [16., 25., 36.],\n",
      "        [49., 64., 81.]])\n",
      "tensor([[0.4406, 0.2065, 0.2424],\n",
      "        [0.1905, 0.9320, 0.5387],\n",
      "        [0.5773, 0.0014, 0.7411]])\n",
      "tensor([[ 1.,  4.,  9.],\n",
      "        [16., 25., 36.],\n",
      "        [49., 64., 81.]])\n"
     ]
    }
   ],
   "source": [
    "# 计算张量逐元素相乘的几种方法。\n",
    "z1 = tensor * tensor\n",
    "z2 = tensor.mul(tensor)\n",
    "z3 = torch.rand_like(tensor)\n",
    "print(z1)\n",
    "print(z2)\n",
    "print(z3)\n",
    "torch.mul(tensor, tensor, out=z3)\n",
    "print(z3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(45.)\n",
      "45.0\n",
      "<class 'float'>\n"
     ]
    }
   ],
   "source": [
    "agg = tensor.sum()\n",
    "print(agg)\n",
    "agg_item = agg.item()\n",
    "print(agg_item)\n",
    "print(type(agg_item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor:  tensor([[ 4.,  5.,  6.],\n",
      "        [ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n",
      "tensor:  tensor([[ 7.,  8.,  9.],\n",
      "        [10., 11., 12.],\n",
      "        [13., 14., 15.]])\n",
      "tenson:  tensor([[ 5.,  6.,  7.],\n",
      "        [ 8.,  9., 10.],\n",
      "        [11., 12., 13.]])\n"
     ]
    }
   ],
   "source": [
    "# In-place操作\n",
    "print(\"tensor: \", tensor)\n",
    "tensor.add_(3)\n",
    "print(\"tensor: \", tensor)\n",
    "tenson = tensor - 2\n",
    "print(\"tenson: \", tenson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([1., 1., 1., 1., 1.])\n",
      "n: [1. 1. 1. 1. 1.]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# 与numpy之间的转换\n",
    "t = torch.ones(5)\n",
    "print(f\"t: {t}\")\n",
    "n = t.numpy()\n",
    "print(f\"n: {n}\")\n",
    "print(type(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# Numpy数组到张量\n",
    "n = np.ones(5)\n",
    "print(type(n))\n",
    "t = torch.from_numpy(n)\n",
    "print(t)\n",
    "print(type(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7001, -0.6774,  0.5869, -0.8031, -1.7564, -1.2646, -2.2095, -0.2889,\n",
      "         -1.7938, -0.8510],\n",
      "        [-0.5056,  1.8471, -1.8398,  1.7961,  0.9302, -0.3732, -1.4352, -0.5111,\n",
      "         -2.1559, -0.7353],\n",
      "        [ 0.0473,  0.5934,  0.9535, -1.3326,  0.1812, -0.1191,  0.5387,  1.4252,\n",
      "          0.8257,  0.0101],\n",
      "        [-0.5305, -0.1641, -0.1918,  0.2336, -0.2381, -0.7834, -1.1396, -0.3506,\n",
      "         -0.7392,  1.2957],\n",
      "        [-0.1974, -0.8036, -0.0988, -1.5215, -0.9537,  1.0805, -1.0337, -0.2532,\n",
      "          0.9586,  0.0350],\n",
      "        [-0.6232, -1.1874,  1.0203,  0.0596, -2.3049, -0.7731, -0.1611,  0.4482,\n",
      "          1.0059, -1.2191],\n",
      "        [-0.3399, -1.2490,  1.0138, -1.2708,  0.2763,  1.0642,  0.6759, -2.1069,\n",
      "          1.5509, -0.4469],\n",
      "        [ 1.0258,  0.1294, -0.7182, -0.2828, -0.9816, -1.1595, -1.4077, -0.0624,\n",
      "         -0.6119,  0.4205],\n",
      "        [ 0.0709,  1.0023,  0.7420,  0.0270,  0.8310,  1.2163, -1.9146,  0.6482,\n",
      "         -1.2403,  0.6824],\n",
      "        [-0.6901, -0.9065,  1.1939, -0.0874,  1.0855,  0.0679, -0.1678, -0.0176,\n",
      "         -0.8446, -0.8745]], requires_grad=True)\n",
      "tensor([-2.2283, -0.4433, -1.2016, -0.8929,  1.9666,  1.7378, -0.5759,  0.1780,\n",
      "        -0.0471, -0.9973], requires_grad=True)\n",
      "tensor([-0.4407], requires_grad=True)\n",
      "tensor([-0.7035,  0.3316,  1.5868, -1.0043, -0.4071, -1.1284, -0.1475, -0.5765,\n",
      "        -1.9294, -1.8313], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiong\\AppData\\Local\\Temp\\ipykernel_18388\\2826643257.py:14: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3701.)\n",
      "  result = torch.matmul(x, m.T) + torch.matmul(y,m) + z\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'expression.png'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pythorch计算图可视化\n",
    "import torch \n",
    "from torchviz import make_dot\n",
    "# 定义矩阵x,向量y,和常数z\n",
    "x = torch.randn(10,10,requires_grad=True)\n",
    "y = torch.randn(10,requires_grad=True)\n",
    "z = torch.randn(1,requires_grad=True)\n",
    "m = torch.randn(10,requires_grad=True)\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)\n",
    "print(m)\n",
    "# 计算 m^T * x + y * m + z\n",
    "result = torch.matmul(x, m.T) + torch.matmul(y,m) + z\n",
    "\n",
    "# 生成计算图节点\n",
    "dot = make_dot(result, params={'x': x, 'y': y, 'z': z, 'm':m})\n",
    "# 绘制计算\n",
    "dot.render('expression', format='png', cleanup=True, view=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
