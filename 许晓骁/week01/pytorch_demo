import torch
import numpy as np
from torchviz import make_dot


# 创建一个2x3的张量，内容为[[1, 2, 3], [4, 5, 6]]，数据类型为 float32
data = torch.tensor([[1,2,3],[4,5,6]], dtype=torch.float32)
print(data)

# NumPy数组转换为PyTorch张量
np_array = np.array([[1,2,3],[4,5,6]])
data2 = torch.from_numpy(np_array)
print(data2)

# 通过已知张量维度，创建新张量
data3 = torch.rand_like(data2, dtype=torch.float)
print(data3)

# 定义张量的形状
shape = (2,3)
# 创建一个形状为 (2, 3) 的随机张量
rand_tensor = torch.rand(shape)
# 创建一个形状为 (2, 3) 的全1张量
ones_tensor = torch.ones(shape)
# 创建一个形状为 (2, 3) 的全0张量
zeros_tensor = torch.zeros(shape)
print(f"Random Tensor: {rand_tensor}")
print(f"Ones Tensor: {ones_tensor}")
print(f"Zeros Tensor: {zeros_tensor}")


# 基于现有tensor构建，但使用新值填充
m = torch.ones(5,3, dtype=torch.double)
n = torch.rand_like(m, dtype=torch.float)
# 获取tensor的大小
print(m.size()) # torch.Size([5,3])
# 创建一个形状为 (5, 3) 的随机张量，元素值在 [0, 1) 范围内
print(torch.rand(5,3))
# 创建一个形状为 (5, 3) 的标准正态分布随机张量
print(torch.randn(5,3))
# 创建一个形状为 (5, 3) 的正态分布随机张量，均值为 0，标准差为 1
print(torch.normal(mean=.0,std=1.0,size=(5,3)))
# 创建一个从 1 到 10 的张量，包含 21 个均匀分布的点
# 线性间隔向量(返回一个1维张量，包含在区间start和end上均匀间隔的steps个点)
print(torch.linspace(start=1,end=10,steps=21))


tensor = torch.rand(3,4)
print(f"Shape of tensor: {tensor.shape}")
print(f"Datatype of tensor: {tensor.dtype}")
#tensor.device 返回张量存储的设备信息，通常为 cpu，表示该张量存储在CPU上。如果张量被移动到GPU上，输出将显示为 cuda:0 或其他CUDA设备
print(f"Device tensor is stored on: {tensor.device}")

# 检查pytorch是否支持GPU
if torch.cuda.is_available():
    device = torch.device("cuda")
    tensor = tensor.to(device)
print(tensor)
print(tensor.device)
# mac上没有GPU，使用M系列芯片
# if torch.backends.mps.is_available():
#     device = torch.device("mps")
#     tensor = tensor.to(device)
# print(tensor)
# print(tensor.device)


tensor = torch.ones(4, 4)
print(tensor)
# 输出第一行
print('First row: ', tensor[0])
print('First column: ', tensor[:, 0])
print('Last column:', tensor[..., -1])
# 将第二列的所有元素设置为0
tensor[:,1] = 0
print(tensor)

# torch.cat 函数将多个张量沿指定维度进行拼接
# 沿着列的方向（dim=1）拼接三个 tensor，此时是4x12
t1 = torch.cat([tensor, tensor, tensor], dim=1)
print(t1)
print(t1 * 3)
print(t1.shape)


# 创建一个形状为 (3, 3) 的张量，元素为 1 到 9
tensor = torch.arange(1,10, dtype=torch.float32).reshape(3, 3)
print(tensor)
# 计算两个张量之间矩阵乘法的几种方式。 y1, y2, y3 最后的值是一样的 dot
y1 = tensor @ tensor.T
y2 = tensor.matmul(tensor.T)
y3 = torch.rand_like(tensor)
# 将矩阵乘法的结果存储到 y3 中
torch.matmul(tensor, tensor.T, out=y3)
# 计算张量逐元素相乘的几种方法。 z1, z2, z3 最后的值是一样的。
z1 = tensor * tensor
z2 = tensor.mul(tensor)
z3 = torch.rand_like(tensor)
torch.mul(tensor, tensor, out=z3)
print(z1)
print(z3)


# 计算张量的总和
agg = tensor.sum()
# 将总和转换为 Python 原生数据类型
agg_item = agg.item()
print(agg_item, type(agg_item))


print(tensor)
#tensor.add_(5)
tensor = tensor + 5
# tensor += 5
print(tensor)


# 定义矩阵 A，向量 b 和常数 c
A = torch.randn(10, 10,requires_grad=True)  # requires_grad=True 表示我们要对 A 求导
b = torch.randn(10,requires_grad=True)
c = torch.randn(1,requires_grad=True)
x = torch.randn(10, requires_grad=True)
# 计算 x^T * A + b * x + c
result = torch.matmul(A, x.T) + torch.matmul(b, x) + c
# 生成计算图节点
dot = make_dot(result, params={'A': A, 'b': b, 'c': c, 'x': x})
# 绘制计算图
dot.render('expression', format='png', cleanup=True, view=False)
